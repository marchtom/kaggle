{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D, Concatenate, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.initializers import he_normal\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.applications.nasnet import NASNetLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(path, size=0):\n",
    "    fileDataTrain = path\n",
    "\n",
    "    inputTrainRaw = pd.read_json(fileDataTrain)\n",
    "\n",
    "    inputTrainRaw.inc_angle.replace('na', 0, inplace=True)\n",
    "    inputTrainRaw.inc_angle = inputTrainRaw.inc_angle.astype(float).fillna(0.0)\n",
    "\n",
    "    inputTrain = inputTrainRaw[inputTrainRaw['inc_angle'] > 0]\n",
    "\n",
    "    inputTrain['band_3'] = [(np.array(b1) + np.array(b2))/2 for b1, b2 in zip(inputTrain['band_1'], inputTrain['band_2'])]\n",
    "\n",
    "    x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in inputTrain[\"band_1\"]])\n",
    "    x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in inputTrain[\"band_2\"]])\n",
    "    x_band3 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in inputTrain[\"band_3\"]])\n",
    "\n",
    "    if size:\n",
    "        x_band1 = np.array([cv2.resize(img, (size, size), interpolation = cv2.INTER_CUBIC) for img in x_band1])\n",
    "        x_band2 = np.array([cv2.resize(img, (size, size), interpolation = cv2.INTER_CUBIC) for img in x_band2])\n",
    "        x_band3 = np.array([cv2.resize(img, (size, size), interpolation = cv2.INTER_CUBIC) for img in x_band3])\n",
    "    \n",
    "\n",
    "    x_data = np.concatenate([x_band1[:, :, :, np.newaxis], x_band2[:, :, :, np.newaxis], \n",
    "                             x_band3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "    del inputTrainRaw\n",
    "    del inputTrain\n",
    "    \n",
    "    return np.array(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424/8424 [==============================] - 91s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "train = make_data('./test.json', size=224)\n",
    "train_vgg16 = vgg16.predict(train, verbose=1)\n",
    "vgg16 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/encoded_x_vgg16_test.np', 'wb') as f:\n",
    "    np.save(f, train_vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nasnet = NASNetLarge(weights='imagenet', include_top=False, pooling='avg')\n",
    "train = make_data('./test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1684\n",
      "1684/1684 [==============================] - 115s 68ms/step\n",
      "1684 3368\n",
      "1684/1684 [==============================] - 115s 69ms/step\n",
      "3368 5052\n",
      "1684/1684 [==============================] - 116s 69ms/step\n",
      "5052 6736\n",
      "1684/1684 [==============================] - 115s 68ms/step\n",
      "6736 8420\n",
      "1684/1684 [==============================] - 115s 68ms/step\n"
     ]
    }
   ],
   "source": [
    "ind = int(0.25*len(train))\n",
    "for i in range(0, 4):\n",
    "    print (ind*i, ind*(i+1))\n",
    "    train_part = train[ind*i:ind*(i+1)]\n",
    "    train_part = np.array([cv2.resize(img, (331, 331), interpolation = cv2.INTER_CUBIC) for img in train_part])\n",
    "    train_nasnet = nasnet.predict(train_part, verbose=1)\n",
    "    with open('./encoded_test/encoded_x_nasnet_test_'+str(i)+'.np', 'wb') as f:\n",
    "        np.save(f, train_nasnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "4/4 [==============================] - 0s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "train_part = train[8420:]\n",
    "train_part = np.array([cv2.resize(img, (331, 331), interpolation = cv2.INTER_CUBIC) for img in train_part])\n",
    "train_nasnet = nasnet.predict(train_part, verbose=1)\n",
    "with open('./encoded_test/encoded_x_nasnet_test_5.np', 'wb') as f:\n",
    "    np.save(f, train_nasnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_out = np.load('./encoded_test/encoded_x_nasnet_test_0.np')\n",
    "for i in range(1, 5):\n",
    "    name = f'./encoded_test/encoded_x_nasnet_test_{i}.np'\n",
    "    new_tab = np.load(name)\n",
    "    conc_out = np.concatenate((conc_out, new_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/encoded_x_nasnet_test.np', 'wb') as f:\n",
    "    np.save(f, conc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424/8424 [==============================] - 107s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGG19(weights='imagenet', include_top=False, pooling='avg')\n",
    "train = make_data('./test.json', size=224)\n",
    "train_vgg19 = vgg19.predict(train, verbose=1)\n",
    "del vgg19\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/encoded_x_vgg19_test.np', 'wb') as f:\n",
    "    np.save(f, train_vgg19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2106\n",
      "2106/2106 [==============================] - 44s 21ms/step\n",
      "2106 4212\n",
      "2106/2106 [==============================] - 42s 20ms/step\n",
      "4212 6318\n",
      "2106/2106 [==============================] - 42s 20ms/step\n",
      "6318 8424\n",
      "2106/2106 [==============================] - 42s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "xception = Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "train = make_data('./test.json')\n",
    "#train_xception = xception.predict(train, verbose=1)\n",
    "ind = int(0.25*len(train))\n",
    "for i in range(0, 4):\n",
    "    print (ind*i, ind*(i+1))\n",
    "    train_part = train[ind*i:ind*(i+1)]\n",
    "    train_part = np.array([cv2.resize(img, (299, 299), interpolation = cv2.INTER_CUBIC) for img in train_part])\n",
    "    train_nasnet = xception.predict(train_part, verbose=1)\n",
    "    with open('./encoded_test/xception_parts/encoded_x_xception_test_'+str(i)+'.np', 'wb') as f:\n",
    "        np.save(f, train_nasnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_out = np.load('./encoded_test/xception_parts/encoded_x_xception_test_0.np')\n",
    "for i in range(1, 4):\n",
    "    name = f'./encoded_test/xception_parts/encoded_x_xception_test_{i}.np'\n",
    "    new_tab = np.load(name)\n",
    "    conc_out = np.concatenate((conc_out, new_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424, 2048)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/encoded_x_xception_test.np', 'wb') as f:\n",
    "    np.save(f, conc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2106\n",
      "2106/2106 [==============================] - 27s 13ms/step\n",
      "2106 4212\n",
      "2106/2106 [==============================] - 24s 11ms/step\n",
      "4212 6318\n",
      "2106/2106 [==============================] - 24s 11ms/step\n",
      "6318 8424\n",
      "2106/2106 [==============================] - 24s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "inception = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "train = make_data('./test.json')\n",
    "#train_inception = inception.predict(train, verbose=1)\n",
    "ind = int(0.25*len(train))\n",
    "for i in range(0, 4):\n",
    "    print (ind*i, ind*(i+1))\n",
    "    train_part = train[ind*i:ind*(i+1)]\n",
    "    train_part = np.array([cv2.resize(img, (299, 299), interpolation = cv2.INTER_CUBIC) for img in train_part])\n",
    "    train_nasnet = inception.predict(train_part, verbose=1)\n",
    "    with open('./encoded_test/inception_parts/encoded_x_inception_test_'+str(i)+'.np', 'wb') as f:\n",
    "        np.save(f, train_nasnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_out = np.load('./encoded_test/inception_parts/encoded_x_inception_test_0.np')\n",
    "for i in range(1, 4):\n",
    "    name = f'./encoded_test/inception_parts/encoded_x_inception_test_{i}.np'\n",
    "    new_tab = np.load(name)\n",
    "    conc_out = np.concatenate((conc_out, new_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/encoded_x_inception_test.np', 'wb') as f:\n",
    "    np.save(f, conc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2106\n",
      "2106/2106 [==============================] - 47s 22ms/step\n",
      "2106 4212\n",
      "2106/2106 [==============================] - 44s 21ms/step\n",
      "4212 6318\n",
      "2106/2106 [==============================] - 45s 21ms/step\n",
      "6318 8424\n",
      "2106/2106 [==============================] - 44s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "InceptionResNetV2 = keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', \n",
    "                                                                             include_top=False, pooling='avg')\n",
    "train = make_data('./test.json')\n",
    "#train_InceptionResNetV2 = InceptionResNetV2.predict(train, verbose=1)\n",
    "ind = int(0.25*len(train))\n",
    "for i in range(0, 4):\n",
    "    print (ind*i, ind*(i+1))\n",
    "    train_part = train[ind*i:ind*(i+1)]\n",
    "    train_part = np.array([cv2.resize(img, (299, 299), interpolation = cv2.INTER_CUBIC) for img in train_part])\n",
    "    train_nasnet = InceptionResNetV2.predict(train_part, verbose=1)\n",
    "    with open('./encoded_test/InceptionResNetV2_parts/encoded_x_InceptionResNetV2_test_'+str(i)+'.np', 'wb') as f:\n",
    "        np.save(f, train_nasnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_out = np.load('./encoded_test/InceptionResNetV2_parts/encoded_x_InceptionResNetV2_test_0.np')\n",
    "for i in range(1, 4):\n",
    "    name = f'./encoded_test/InceptionResNetV2_parts/encoded_x_InceptionResNetV2_test_{i}.np'\n",
    "    new_tab = np.load(name)\n",
    "    conc_out = np.concatenate((conc_out, new_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/encoded_x_InceptionResNetV2_test.np', 'wb') as f:\n",
    "    np.save(f, conc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424/8424 [==============================] - 138s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "DenseNet201 = keras.applications.densenet.DenseNet201(weights='imagenet', \n",
    "                                                      include_top=False, pooling='avg')\n",
    "train = make_data('./test.json', size=224)\n",
    "train_DenseNet201 = DenseNet201.predict(train, verbose=1)\n",
    "DenseNet201 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/encoded_x_DenseNet201_test.np', 'wb') as f:\n",
    "    np.save(f, train_DenseNet201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = make_data('./train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:,:,:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424, 75, 75, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reshape(8424, 75*75*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8424, 11250)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./encoded_test/raw_test.np', 'wb') as f:\n",
    "    np.save(f, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
